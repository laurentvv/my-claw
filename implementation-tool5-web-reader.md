# TOOL-5 â€” Web Reader (VisitWebpageTool) â€” Plan d'implÃ©mentation

> Document pour IA de codage (Claude Code, Cursor, Clineâ€¦)
> Lire AGENTS.md, LEARNING.md, PROGRESS.md et le plan TOOL-4 avant de commencer.
> RÃˆGLE ABSOLUE : TOOL-4 doit Ãªtre validÃ© (âœ… DONE) avant de commencer TOOL-5.
> Python 3.14 â€” uv comme gestionnaire de paquets.

---

## DÃ‰CISION ARCHITECTURALE

**Pourquoi VisitWebpageTool plutÃ´t que MCP Z.ai webReader ?**

| CritÃ¨re            | MCP Z.ai webReader      | VisitWebpageTool (built-in)     |
|--------------------|------------------------|----------------------------------|
| Quota              | 100 calls/mois partagÃ©s | IllimitÃ©                         |
| Configuration      | ZAI_API_KEY requis      | 0 config                         |
| DÃ©pendance         | Service Z.ai            | markdownify>=0.14.1 (dÃ©jÃ  lÃ )   |
| Output             | Texte propre (service)  | Markdown converti depuis HTML    |
| Max output         | GÃ©rÃ© cÃ´tÃ© Z.ai          | max_output_length configurable   |

**DÃ©cision : VisitWebpageTool (built-in smolagents)**

**Important :** TOOL-5 s'intÃ¨gre dans le mÃªme `web_agent` que TOOL-4.
Le web_agent gÃ¨re Ã  la fois DuckDuckGoSearchTool ET VisitWebpageTool.

---

## CONTEXTE PROJET

### Architecture aprÃ¨s TOOL-4 (Ã©tat attendu au dÃ©marrage de TOOL-5)
```
Manager (glm-4.7 / qwen3:8b)
â”œâ”€â”€ pc_control_agent  â†’ qwen3-vl:2b
â”œâ”€â”€ browser_agent     â†’ Nanbeige4.1-3B + 26 tools Chrome DevTools
â””â”€â”€ web_agent         â†’ Nanbeige4.1-3B
    â”œâ”€â”€ âœ… DuckDuckGoSearchTool  (TOOL-4)
    â””â”€â”€ ðŸ”§ VisitWebpageTool     (TOOL-5 â€” ce qu'on ajoute)
```

### Cas d'usage de VisitWebpageTool
- Lire le contenu complet d'une page GitHub (README, fichiers)
- Extraire la documentation d'une URL spÃ©cifique
- VÃ©rifier le contenu d'un article ou d'un rÃ©sultat de recherche
- Scraper une page pour en extraire les informations clÃ©s

### DiffÃ©rence avec browser_agent (Chrome DevTools)
- **browser_agent** : contrÃ´le Chrome interactif, remplir formulaires, cliquer, naviguer
- **web_agent/VisitWebpageTool** : lecture seule du contenu texte d'une URL statique
  â†’ Choisir web_agent pour extraction de texte (plus rapide, pas de Chrome)
  â†’ Choisir browser_agent pour interaction avec la page (connexion, clic, etc.)

---

## STRUCTURE FICHIERS Ã€ CRÃ‰ER / MODIFIER

```
agent/
â”œâ”€â”€ main.py           â† Pas de modification (web_agent dÃ©jÃ  initialisÃ© en TOOL-4)
â”œâ”€â”€ skills.txt        â† Modifier : ajouter skills VisitWebpageTool
â””â”€â”€ agents/
    â””â”€â”€ web_agent.py  â† Modifier : ajouter VisitWebpageTool + mettre Ã  jour instructions
```

**Aucun nouveau fichier de tool** â€” VisitWebpageTool est built-in smolagents.

---

## Ã‰TAPE 1 â€” VÃ©rifier les dÃ©pendances

### 1A â€” VÃ©rifier markdownify installÃ©
```bash
cd agent
uv run python -c "import markdownify; print('markdownify OK')"
```
Si absent :
```bash
uv add "markdownify>=0.14.1"
# ou via toolkit :
uv add "smolagents[toolkit]"
```

### 1B â€” VÃ©rifier import VisitWebpageTool
```bash
uv run python -c "from smolagents import VisitWebpageTool; t = VisitWebpageTool(); print('VisitWebpageTool OK')"
```

### 1C â€” Test rapide de lecture d'URL
```bash
uv run python -c "
from smolagents import VisitWebpageTool
tool = VisitWebpageTool(max_output_length=2000)
result = tool('https://huggingface.co/docs/smolagents/en/reference/default_tools')
print(result[:500])
"
```
Attendu : extrait du contenu de la page en markdown.

**Checkpoint 1** : Les 3 commandes rÃ©ussissent.
Commit : `chore: vÃ©rification dÃ©pendances TOOL-5 OK`

---

## Ã‰TAPE 2 â€” Modifier agents/web_agent.py

TOOL-5 ne crÃ©e pas un nouveau agent â€” il enrichit le web_agent existant (TOOL-4).
Modifier `agent/agents/web_agent.py` pour :
1. Importer VisitWebpageTool
2. Mettre Ã  jour les instructions systÃ¨me
3. Ajouter VisitWebpageTool dans la liste des tools du CodeAgent
4. Mettre Ã  jour les descriptions ManagedAgent

### Code complet mis Ã  jour : agent/agents/web_agent.py

```python
"""
TOOL-4 + TOOL-5 â€” Web Search & Web Reader Agent
- TOOL-4 : DuckDuckGoSearchTool â€” recherche web (0 quota, 0 config)
- TOOL-5 : VisitWebpageTool â€” lecture de page web (0 quota, 0 config)

ModÃ¨le : Nanbeige4.1-3B (validÃ© 2026-02-22, BFCL-V4: 56.5)
"""

from __future__ import annotations

import logging
from typing import TYPE_CHECKING

from smolagents import CodeAgent, DuckDuckGoSearchTool, ManagedAgent, VisitWebpageTool

if TYPE_CHECKING:
    pass

logger = logging.getLogger(__name__)

# â”€â”€ Constantes de configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Limite de sortie VisitWebpageTool
# 40000 chars = dÃ©faut smolagents (~10000 tokens)
# RÃ©duire si le contexte du modÃ¨le est saturÃ© (Nanbeige4.1-3B : 8192 tokens)
_VISIT_MAX_OUTPUT_LENGTH = 8000  # AdaptÃ© pour contexte 8192 tokens Nanbeige

# DuckDuckGo : nombre de rÃ©sultats
_DDG_MAX_RESULTS = 5

# DuckDuckGo : rate limit (1 req/sec Ã©vite les blocages)
_DDG_RATE_LIMIT = 1.0

# â”€â”€ Instructions systÃ¨me du web_agent (TOOL-4 + TOOL-5) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_WEB_AGENT_INSTRUCTIONS = """
Tu es un agent web spÃ©cialisÃ© dans la recherche et la lecture de pages web.

OUTILS DISPONIBLES :

1. web_search(query="...") [DuckDuckGoSearchTool]
   â†’ Recherche web via DuckDuckGo
   â†’ Retourne : titres, URLs, extraits de texte
   â†’ IllimitÃ©, pas de quota

2. visit_webpage(url="https://...") [VisitWebpageTool]
   â†’ Lit le contenu complet d'une URL
   â†’ Retourne : contenu de la page en markdown
   â†’ Limite : 8000 caractÃ¨res de sortie
   â†’ Ne fonctionne pas pour : pages derriÃ¨re login, PDF, images

STRATÃ‰GIE PAR CAS D'USAGE :

â”€â”€ CAS 1 : Trouver des informations gÃ©nÃ©rales â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. web_search(query="sujet prÃ©cis") pour trouver les meilleures URLs
2. visit_webpage(url="url_la_plus_pertinente") pour lire le dÃ©tail
3. final_answer(synthÃ¨se)

Exemple :
```python
results = web_search(query="smolagents ManagedAgent tutorial 2025")
# Extraire la premiÃ¨re URL pertinente des rÃ©sultats
url = "https://huggingface.co/docs/smolagents/..."  # depuis les rÃ©sultats
content = visit_webpage(url=url)
final_answer(f"Voici ce que j'ai trouvÃ© :\\n{content}")
```

â”€â”€ CAS 2 : Lire une URL directe (connue) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Utiliser directement visit_webpage sans passer par web_search.

Exemple :
```python
content = visit_webpage(url="https://github.com/huggingface/smolagents/blob/main/README.md")
final_answer(content)
```

â”€â”€ CAS 3 : Recherche avec plusieurs sources â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```python
results = web_search(query="Nanbeige 3B BFCL benchmark")
# Identifier 2-3 URLs pertinentes
content1 = visit_webpage(url="url_1")
content2 = visit_webpage(url="url_2")
final_answer(f"Source 1:\\n{content1}\\n\\nSource 2:\\n{content2}")
```

RÃˆGLES IMPORTANTES :
- RequÃªtes web_search : courtes (3-6 mots), en anglais si possible
- URLs visit_webpage : complÃ¨tes avec https://
- Ne pas boucler indÃ©finiment â€” max 3 web_search + 3 visit_webpage par tÃ¢che
- Si visit_webpage Ã©choue (timeout, 403, etc.) â†’ essayer une autre URL
- SynthÃ©tiser le contenu, ne pas retourner des blocs bruts de 8000 chars

EXEMPLES DE PROMPTS ET RÃ‰PONSES ATTENDUES :

Prompt : "Quelles sont les nouveautÃ©s Python 3.14 ?"
```python
results = web_search(query="Python 3.14 new features changelog")
url = "https://docs.python.org/3.14/whatsnew/3.14.html"  # depuis rÃ©sultats
content = visit_webpage(url=url)
final_answer(content[:3000])  # limiter pour ne pas surcharger
```

Prompt : "Lis le README de smolagents sur GitHub"
```python
content = visit_webpage(url="https://raw.githubusercontent.com/huggingface/smolagents/main/README.md")
final_answer(content)
```

Prompt : "Cherche et lis la doc de FastAPI lifespan"
```python
results = web_search(query="FastAPI lifespan context manager documentation")
content = visit_webpage(url="https://fastapi.tiangolo.com/advanced/events/")
final_answer(content)
```
"""

# â”€â”€ Factory function â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def create_web_search_managed_agent(
    ollama_url: str,
    model_id: str = "hf.co/tantk/Nanbeige4.1-3B-GGUF:Q4_K_M",
    max_results: int = _DDG_MAX_RESULTS,
    rate_limit: float = _DDG_RATE_LIMIT,
    visit_max_output_length: int = _VISIT_MAX_OUTPUT_LENGTH,
) -> ManagedAgent | None:
    """
    CrÃ©e le ManagedAgent web avec DuckDuckGoSearchTool + VisitWebpageTool.

    TOOL-4 : DuckDuckGoSearchTool  (recherche web)
    TOOL-5 : VisitWebpageTool      (lecture page web)

    Args:
        ollama_url: URL du serveur Ollama
        model_id: ModÃ¨le Ollama (Nanbeige4.1-3B validÃ©)
        max_results: RÃ©sultats max DuckDuckGo (dÃ©faut: 5)
        rate_limit: Rate limit DuckDuckGo req/sec (dÃ©faut: 1.0)
        visit_max_output_length: Limite sortie VisitWebpageTool (dÃ©faut: 8000)

    Returns:
        ManagedAgent configurÃ©, ou None si Ã©chec.

    Note Python 3.14:
        - `X | None` prÃ©fÃ©rÃ© Ã  `Optional[X]` (PEP 604)
        - f-strings imbriquÃ©es supportÃ©es nativement
        - `from __future__ import annotations` pour eval lazy des annotations
    """
    try:
        from smolagents import LiteLLMModel

        model = LiteLLMModel(
            model_id=f"ollama_chat/{model_id}",
            api_base=ollama_url,
            num_ctx=8192,
        )
        logger.info(f"âœ“ ModÃ¨le web_agent chargÃ© : {model_id}")

        # â”€â”€ TOOL-4 : DuckDuckGoSearchTool â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        search_tool = DuckDuckGoSearchTool(
            max_results=max_results,
            rate_limit=rate_limit,
        )
        logger.info(
            f"âœ“ TOOL-4 DuckDuckGoSearchTool configurÃ© "
            f"(max_results={max_results}, rate_limit={rate_limit})"
        )

        # â”€â”€ TOOL-5 : VisitWebpageTool â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        visit_tool = VisitWebpageTool(
            max_output_length=visit_max_output_length,
        )
        logger.info(
            f"âœ“ TOOL-5 VisitWebpageTool configurÃ© "
            f"(max_output_length={visit_max_output_length})"
        )

        # â”€â”€ CodeAgent avec les 2 tools â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        web_agent = CodeAgent(
            tools=[search_tool, visit_tool],  # TOOL-4 + TOOL-5
            model=model,
            name="web_search",
            description=(
                "Agent web : recherche et lecture de pages web. "
                "Outils : DuckDuckGoSearchTool (recherche) + VisitWebpageTool (lecture URL). "
                "IllimitÃ©, pas de quota."
            ),
            system_prompt=_WEB_AGENT_INSTRUCTIONS,
            max_steps=8,        # Plus Ã©levÃ© pour les tÃ¢ches search+visit (2 Ã©tapes min)
            verbosity_level=1,
        )
        logger.info("âœ“ web_agent crÃ©Ã© avec DuckDuckGoSearchTool + VisitWebpageTool")

        # â”€â”€ ManagedAgent â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        managed_agent = ManagedAgent(
            agent=web_agent,
            name="web_search",
            description=(
                "Agent web pour recherche et lecture de pages. CapacitÃ©s :\n"
                "- Recherche web via DuckDuckGo (TOOL-4)\n"
                "- Lecture du contenu d'une URL (TOOL-5)\n"
                "- Combinaison : rechercher puis lire la page la plus pertinente\n\n"
                "Exemples d'utilisation :\n"
                "- 'Quelles sont les nouveautÃ©s smolagents ?'\n"
                "- 'Lis le README de https://github.com/...'\n"
                "- 'Cherche et lis la doc FastAPI lifespan'\n"
                "- 'Prix Bitcoin aujourd'hui'\n"
                "- 'Benchmarks Nanbeige4.1-3B 2025'\n\n"
                "Ne pas utiliser pour : interactions avec des pages web (clic, formulaires) "
                "â†’ utiliser browser_agent dans ce cas."
            ),
            additional_prompting=(
                "Formule des requÃªtes web_search courtes (3-6 mots). "
                "Pour visit_webpage, fournis des URLs complÃ¨tes avec https://. "
                "SynthÃ©tise les rÃ©sultats au lieu de retourner du texte brut."
            ),
        )

        logger.info("âœ“ ManagedAgent web_search crÃ©Ã© (TOOL-4 + TOOL-5)")
        return managed_agent

    except ImportError as e:
        logger.error(f"âœ— Import manquant pour web_agent : {e}")
        if "markdownify" in str(e):
            logger.error("  â†’ uv add 'markdownify>=0.14.1' pour VisitWebpageTool")
        elif "ddgs" in str(e) or "duckduckgo" in str(e):
            logger.error("  â†’ uv add 'ddgs>=9.0.0' pour DuckDuckGoSearchTool")
        else:
            logger.error("  â†’ uv add 'smolagents[toolkit]' pour tous les built-in tools")
        return None
    except Exception as e:
        logger.error(f"âœ— Ã‰chec crÃ©ation web_agent : {e}")
        return None


# â”€â”€ Diagnostic autonome â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def diagnose_web_tools() -> dict[str, bool | str | None]:
    """
    Diagnostique la disponibilitÃ© des outils web built-in.
    UtilisÃ© par /health et /models.

    Returns:
        dict avec l'Ã©tat de chaque tool.
    """
    result: dict[str, bool | str | None] = {}

    # TOOL-4 : DuckDuckGoSearchTool
    try:
        from duckduckgo_search import DDGS  # noqa: F401
        result["tool4_ddg"] = True
        result["tool4_ddg_name"] = "DuckDuckGoSearchTool"
        result["tool4_ddg_error"] = None
    except ImportError as e:
        result["tool4_ddg"] = False
        result["tool4_ddg_error"] = str(e)

    # TOOL-5 : VisitWebpageTool
    try:
        import markdownify  # noqa: F401
        result["tool5_visit"] = True
        result["tool5_visit_name"] = "VisitWebpageTool"
        result["tool5_visit_error"] = None
    except ImportError as e:
        result["tool5_visit"] = False
        result["tool5_visit_error"] = str(e)

    result["web_agent_ready"] = result.get("tool4_ddg", False) and result.get("tool5_visit", False)
    result["quota"] = "illimitÃ© (DuckDuckGo + markdownify, 0 API key)"

    return result


# â”€â”€ CompatibilitÃ© TOOL-4 seul (alias pour rÃ©trocompatibilitÃ©) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Alias utilisÃ© si main.py appelle encore l'ancienne signature TOOL-4 seule
# Ã€ supprimer aprÃ¨s validation TOOL-5
diagnose_web_search = diagnose_web_tools
```

---

## Ã‰TAPE 3 â€” Pas de modification de main.py

TOOL-5 rÃ©utilise exactement la mÃªme factory `create_web_search_managed_agent()`.
La signature de la fonction n'a pas changÃ© (nouveaux params ont des valeurs par dÃ©faut).

VÃ©rifier simplement que l'appel dans main.py n'a pas de paramÃ¨tres hardcodÃ©s qui
empÃªcheraient VisitWebpageTool de s'initialiser :

```python
# Dans main.py â€” lifespan startup â€” aucun changement nÃ©cessaire
managed_web = create_web_search_managed_agent(
    ollama_url=ollama_url,
    # Les paramÃ¨tres TOOL-5 ont des valeurs par dÃ©faut :
    # visit_max_output_length=8000  â† dÃ©faut configurÃ© dans web_agent.py
)
```

**Mettre Ã  jour la description dans /models :**
```python
"web_search": "Nanbeige4.1-3B + DuckDuckGoSearchTool + VisitWebpageTool (illimitÃ©)",
```

**Mettre Ã  jour /health pour inclure VisitWebpageTool :**
```python
@app.get("/health")
async def health():
    web_diag = diagnose_web_tools()  # â† signature mise Ã  jour
    return {
        "status": "ok",
        "agents": {
            "web_search": _web_search_agent is not None,
        },
        "tools": {
            "web_search_ddg": web_diag.get("tool4_ddg", False),
            "web_visit": web_diag.get("tool5_visit", False),
            "web_agent_ready": web_diag.get("web_agent_ready", False),
        },
    }
```

**Checkpoint 3** : RedÃ©marrer le serveur, vÃ©rifier logs :
```
âœ“ TOOL-4 DuckDuckGoSearchTool configurÃ© (max_results=5, rate_limit=1.0)
âœ“ TOOL-5 VisitWebpageTool configurÃ© (max_output_length=8000)
âœ“ web_agent crÃ©Ã© avec DuckDuckGoSearchTool + VisitWebpageTool
âœ“ ManagedAgent web_search crÃ©Ã© (TOOL-4 + TOOL-5)
```
Commit : `feat(tool-5): VisitWebpageTool ajoutÃ© au web_agent`

---

## Ã‰TAPE 4 â€” Mettre Ã  jour skills.txt

Ajouter aprÃ¨s les skills TOOL-4 dans `agent/skills.txt` :

```
â”€â”€ TOOL-5 : Lecture de Page Web (VisitWebpageTool) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SKILL 14 : Lire le contenu d'une URL
Utiliser visit_webpage pour extraire le texte d'une page web connue.
Passer l'URL complÃ¨te au web_search agent.

QUAND UTILISER :
- Lire le README d'un repo GitHub
- Extraire le contenu d'une documentation officielle
- VÃ©rifier le contenu d'un article trouvÃ© via web_search
- Lire une page de rÃ©sultat de recherche en dÃ©tail

COMMENT FORMULER :
âœ… "Lis le README de https://github.com/huggingface/smolagents"
âœ… "Lis la doc officielle de smolagents sur huggingface.co"
âœ… "Cherche les benchmarks Nanbeige puis lis la page la plus pertinente"
âŒ "TÃ©lÃ©charge le PDF de..." (VisitWebpageTool ne gÃ¨re pas les PDF)
âŒ "Clique sur le bouton..." (utiliser browser_agent pour les interactions)

SKILL 15 : Workflow Search + Read (Pattern recommandÃ©)
Combiner TOOL-4 et TOOL-5 pour un workflow complet :
1. web_search(query="...") â†’ trouver les meilleures URLs
2. visit_webpage(url="...") â†’ lire le contenu de l'URL la plus pertinente
3. SynthÃ©tiser et retourner

Exemple de prompt utilisateur : "Quelles sont les nouveautÃ©s de smolagents v1.24 ?"
â†’ Le web_agent fait : search("smolagents 1.24 changelog") puis visit(url du changelog)

SKILL 16 : Lecture de raw GitHub
Pour lire des fichiers GitHub directement (code, markdown) :
âœ… URL raw : https://raw.githubusercontent.com/user/repo/main/file.py
âœ… "Lis le fichier web_agent.py dans le repo my-claw sur GitHub"

NOTE : VisitWebpageTool ne lit pas les pages derriÃ¨re authentification.
Pour GitHub privÃ© ou pages protÃ©gÃ©es â†’ utiliser browser_agent.
```

---

## Ã‰TAPE 5 â€” Tests de validation

### 5A â€” Test VisitWebpageTool seul (URL directe)
Via Gradio :
```
Lis le contenu de https://huggingface.co/docs/smolagents/en/reference/default_tools
```
Attendu : extrait de la doc smolagents en markdown, avec liste des tools disponibles.

### 5B â€” Test workflow complet Search + Visit
```
Cherche les derniÃ¨res nouveautÃ©s de smolagents puis lis la page la plus pertinente
```
Attendu en logs :
```
web_agent â†’ web_search(query="smolagents latest release 2025")
web_agent â†’ visit_webpage(url="https://github.com/huggingface/smolagents/releases")
â†’ final_answer(contenu du changelog)
```

### 5C â€” Test lecture fichier GitHub raw
```
Lis le README de smolagents sur GitHub
```
Attendu :
```
web_agent â†’ visit_webpage(url="https://raw.githubusercontent.com/huggingface/smolagents/main/README.md")
â†’ contenu du README retournÃ©
```

### 5D â€” Test gestion d'erreur (URL invalide)
```
Lis le contenu de https://cette-url-nexiste-pas-12345.xyz
```
Attendu : le web_agent retourne une erreur claire, pas un crash.
Log attendu : erreur mentionnÃ©e dans le final_answer, pas d'exception non gÃ©rÃ©e.

### 5E â€” Test dÃ©lÃ©gation correcte (ne pas utiliser pour les clics)
```
Va sur GitHub et connecte-toi Ã  mon compte
```
Attendu : le Manager dÃ©lÃ¨gue Ã  browser_agent (pas au web_agent),
car VisitWebpageTool ne gÃ¨re pas les authentifications.

### 5F â€” VÃ©rification /health
```bash
curl http://localhost:8000/health
```
Attendu :
```json
{
  "tools": {
    "web_search_ddg": true,
    "web_visit": true,
    "web_agent_ready": true
  }
}
```

Commit : `feat: tool-5 â€” VisitWebpageTool validÃ©`

---

## Ã‰TAPE 6 â€” Mettre Ã  jour PROGRESS.md

```markdown
### TOOL-5 â€” Web Reader (VisitWebpageTool built-in)
**Statut : âœ… DONE**

DÃ©cision : built-in smolagents plutÃ´t que MCP Z.ai webReader.
- 0 quota (Ã©conomise les calls Z.ai pour TOOL-6 Zread)
- 0 config (markdownify>=0.14.1 dÃ©jÃ  dÃ©clarÃ© via smolagents[toolkit])
- IntÃ©grÃ© dans le mÃªme web_agent que TOOL-4

IntÃ©gration :
- agent/agents/web_agent.py â†’ tools=[DuckDuckGoSearchTool, VisitWebpageTool]
- VisitWebpageTool(max_output_length=8000) â€” adaptÃ© pour contexte 8192 Nanbeige
- MÃªme ManagedAgent "web_search" â€” pas de nouvel agent crÃ©Ã©
- Workflow combinÃ© : search() puis visit() dans le mÃªme CodeAgent

Checkpoints validÃ©s :
- âœ… markdownify installÃ©, import OK
- âœ… Logs startup : "âœ“ TOOL-5 VisitWebpageTool configurÃ©"
- âœ… "Lis https://..." â†’ contenu de la page en markdown
- âœ… Workflow Search + Visit dans le mÃªme agent
- âœ… Gestion d'erreur URL invalide (pas de crash)
- âœ… /health retourne "web_visit": true
- âœ… Commit : feat: tool-5 â€” VisitWebpageTool validÃ©

Prochaine Ã©tape : TOOL-6 (Zread GitHub via MCP Z.ai â€” les 100 calls Ã©conomisÃ©s)
```

---

## Ã‰TAPE 7 â€” Mettre Ã  jour LEARNING.md

```markdown
## TOOL-5 â€” VisitWebpageTool (2026-02-23)

### IntÃ©gration dans le mÃªme agent que TOOL-4

Pattern recommandÃ© : un seul CodeAgent avec plusieurs tools built-in.
Ne pas crÃ©er un agent sÃ©parÃ© pour chaque outil â€” cela surcharge le Manager.

```python
web_agent = CodeAgent(
    tools=[
        DuckDuckGoSearchTool(max_results=5),  # TOOL-4
        VisitWebpageTool(max_output_length=8000),  # TOOL-5
    ],
    model=model_nanbeige,
    name="web_search",
    max_steps=8,  # Plus Ã©levÃ© car search + visit = 2 steps min
)
```

### max_output_length : calibrer selon le contexte du modÃ¨le

VisitWebpageTool.max_output_length (dÃ©faut smolagents : 40000 chars).
Nanbeige4.1-3B a un contexte de 8192 tokens â‰ˆ 32000 chars.
Mais le contexte est partagÃ© avec l'historique + les instructions.
Valeur safe pour Nanbeige : **8000 chars** (â‰ˆ 2000 tokens de contenu).

Si saturation du contexte : rÃ©duire Ã  4000.
Si rÃ©sultats trop tronquÃ©s : augmenter Ã  12000 (avec modÃ¨le Ã  plus grand contexte).

### DiffÃ©rence web_agent vs browser_agent

| Cas d'usage                    | Agent recommandÃ©  |
|--------------------------------|-------------------|
| Lire le texte d'une URL        | web_agent (TOOL-5)|
| Chercher des infos sur le web  | web_agent (TOOL-4)|
| Cliquer sur un bouton          | browser_agent     |
| Remplir un formulaire          | browser_agent     |
| Se connecter Ã  un compte       | browser_agent     |
| Scraper une SPA (JavaScript)   | browser_agent     |

### URLs raw GitHub pour lire des fichiers

VisitWebpageTool peut lire directement les fichiers GitHub via raw.githubusercontent.com :
```python
visit_webpage(url="https://raw.githubusercontent.com/user/repo/branch/file.py")
```
Utile pour lire le code sans passer par l'API GitHub (TOOL-6 Zread pour repos privÃ©s).

### max_steps=8 pour les workflows combinÃ©s

Un workflow search + visit = minimum 2 steps :
- Step 1 : web_search()
- Step 2 : visit_webpage()
- Step 3 : final_answer()

Mettre max_steps=5 (TOOL-4 seul) â†’ max_steps=8 (TOOL-4 + TOOL-5).
```

---

## RÃ‰CAPITULATIF ORDRE D'IMPLÃ‰MENTATION

```
PRÃ‰-REQUIS : TOOL-4 validÃ© (âœ… DONE dans PROGRESS.md)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Ã‰TAPE 1  VÃ©rifier markdownify installÃ©
Ã‰TAPE 2  Modifier agents/web_agent.py (code complet fourni ci-dessus)
         â†’ Ajouter VisitWebpageTool dans tools[]
         â†’ Mettre Ã  jour instructions systÃ¨me
         â†’ Mettre Ã  jour descriptions ManagedAgent
         â†’ max_steps=8 (au lieu de 5)
Ã‰TAPE 3  Mettre Ã  jour /health et /models dans main.py (descriptions)
         â†’ Pas de nouveau bloc lifespan nÃ©cessaire
Ã‰TAPE 4  Ajouter skills 14-16 dans skills.txt
Ã‰TAPE 5  Tests de validation (5A â†’ 5F)
Ã‰TAPE 6  Mettre Ã  jour PROGRESS.md
Ã‰TAPE 7  Mettre Ã  jour LEARNING.md
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â†’ CHECKPOINT FINAL validÃ© â†’ commit â†’ passer TOOL-6 (MCP Zread Z.ai)
```

---

## NOTES IMPORTANTES POUR L'IA DE CODAGE

1. **Ne pas crÃ©er** de deuxiÃ¨me ManagedAgent pour VisitWebpageTool â€” mÃªme agent que TOOL-4
2. **Ne pas modifier** main.py dans lifespan â€” create_web_search_managed_agent() n'a pas changÃ© de signature
3. **max_output_length=8000** est calibrÃ© pour Nanbeige4.1-3B (contexte 8192 tokens)
4. **max_steps doit passer Ã  8** (Ã©tait 5 pour TOOL-4 seul) â€” search+visit = 2-3 steps
5. **diagnose_web_search() devient diagnose_web_tools()** â€” alias rÃ©trocompatible fourni
6. **Ne pas utiliser VisitWebpageTool pour les PDF** â€” il retourne le binaire ou Ã©choue
7. **Python 3.14** : `X | None`, f-strings imbriquÃ©es, `from __future__ import annotations`
8. **uv** est le gestionnaire de paquets â€” pas pip
9. **Ne pas modifier** TOOL-1/2/3/7/8/9/10 â€” validÃ©s et stables
10. **TOOL-6** (Zread GitHub MCP Z.ai) utilise les 100 calls Z.ai Ã©conomisÃ©s â€” plan sÃ©parÃ© Ã  venir
