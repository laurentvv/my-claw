# my-claw ü¶û

Un assistant personnel minimaliste, auto-h√©berg√© et respectueux de la vie priv√©e, con√ßu pour Windows.

**my-claw** est un assistant hybride puissant qui combine une interface moderne en Next.js 16 avec un "cerveau" Python propuls√© par `smolagents`. Il est con√ßu pour fonctionner enti√®rement sur votre propre mat√©riel, garantissant que vos donn√©es ne quittent jamais votre machine, sauf si vous choisissez explicitement d'utiliser des mod√®les cloud optionnels.

---

## ‚ú® Fonctionnalit√©s Cl√©s

- üõ°Ô∏è **Privacy-First** : Con√ßu pour fonctionner √† 100% localement avec Ollama.
- ü™ü **Int√©gration Windows Profonde** : Acc√®s complet au syst√®me de fichiers, √† PowerShell, au presse-papier et √† l'√©cran.
- üß† **Cerveau Hybride** : Utilise `smolagents` pour une utilisation intelligente des outils et l'ex√©cution de code.
- üåê **Interface Web Moderne** : Interface propre et r√©active construite avec Next.js 16 et Tailwind CSS 4.
- üîå **Outils Extensibles** : Supporte les outils Python personnalis√©s et les int√©grations Model Context Protocol (MCP).
- ü§ñ **Support Multi-Mod√®les** : Support natif pour Qwen3, Gemma3 et GLM-4.7 (via Z.ai).

---

## üöÄ D√©marrage Rapide

### Pr√©requis

- **Node.js** : 25.x ou sup√©rieur
- **uv** : [Gestionnaire de paquets Python](https://docs.astral.sh/uv/)
- **Python** : 3.14.2
- **Ollama** : Pour l'acc√©l√©ration locale des LLM
- **Windows OS** : Recommand√© (pour le support natif des outils)

### Installation

Le projet inclut un script d'installation automatique pour plus de commodit√© :

```powershell
./setup.ps1
```

Ce script va :
1. Initialiser l'environnement de la Gateway (Next.js) et ses d√©pendances.
2. Configurer l'environnement de l'Agent (Python) via `uv`.
3. Configurer la base de donn√©es SQLite avec Prisma 7.4.
4. Pr√©parer vos fichiers `.env`.

---

## üèóÔ∏è Architecture

Le syst√®me est divis√© en deux composants principaux : la **Gateway** (gestion de l'UI et de la m√©moire) et l'**Agent** (gestion du raisonnement et des outils).

```mermaid
graph TD
    User([Utilisateur])
    WebChat[Next.js 16 WebChat]
    NCTalk[Nextcloud Talk - Roadmap]

    subgraph Gateway ["Gateway (Next.js 16)"]
        API_Chat[API /api/chat]
        API_Webhook[API /api/webhook - Roadmap]
        Prisma[Prisma 7 + SQLite]
    end

    subgraph Agent ["Agent (Python 3.14)"]
        FastAPI[Serveur FastAPI]
        Smolagents[smolagents CodeAgent]
        Tools[Outils Windows & MCP]
    end

    subgraph Local ["Services Locaux"]
        Ollama[Ollama - Qwen3/Gemma3]
    end

    subgraph Cloud ["Externe (Optionnel)"]
        ZAI[Z.ai GLM-4.7]
    end

    User --> WebChat
    User -.-> NCTalk
    WebChat --> API_Chat
    NCTalk -.-> API_Webhook
    API_Chat --> Prisma
    API_Chat --> FastAPI
    API_Webhook -.-> FastAPI
    FastAPI --> Smolagents
    Smolagents --> Tools
    Smolagents --> Ollama
    Smolagents --> ZAI
    Tools --> Windows[Windows OS]
    Tools --> Chrome[Chrome DevTools]

    style NCTalk stroke-dasharray: 5 5
    style API_Webhook stroke-dasharray: 5 5
```

---

## ‚öôÔ∏è Configuration des Mod√®les

### Mod√®le par D√©faut

Le mod√®le par d√©faut pour le manager et tous les sous-agents est **glm-4.7 (reason)** si `ZAI_API_KEY` est configur√©, sinon **qwen3:8b** (local).

Vous pouvez changer le mod√®le par d√©faut en d√©finissant la variable d'environnement `DEFAULT_MODEL` dans `agent/.env` :

```bash
# Utiliser glm-4.7 (recommand√©)
DEFAULT_MODEL=reason

# Utiliser glm-4.7-flash (plus rapide)
DEFAULT_MODEL=code

# Utiliser qwen3:8b (local, gratuit)
DEFAULT_MODEL=main
```

### Mod√®les Disponibles

| Cat√©gorie | Mod√®le | Type | Description |
|-----------|--------|------|-------------|
| reason | glm-4.7 | Cloud | Raisonnement profond (d√©faut avec cl√© API) |
| code | glm-4.7-flash | Cloud | Codage rapide |
| main | qwen3:8b | Local | Mod√®le principal (d√©faut sans cl√© API) |
| vision | qwen3-vl:8b | Local | Vision locale |
| smart | qwen3:14b / 8b | Local | Assistant intelligent quotidien (14b recommand√©) |
| fast | gemma3:4b / latest | Local | R√©ponses ultra-rapides |

### Choix Intelligent du Mod√®le

Le syst√®me d√©tecte automatiquement les capacit√©s de votre mat√©riel. Pour un usage local :
- **Haut de gamme (16GB+ VRAM)** : Utilisez `qwen3:14b` pour les t√¢ches `main` et `smart`.
- **Milieu de gamme (8GB VRAM)** : Utilisez `qwen3:8b` pour une exp√©rience √©quilibr√©e.
- **Entr√©e de gamme / Vitesse** : Utilisez `gemma3:4b` ou `Nanbeige4.1-3B` pour des r√©ponses quasi-instantan√©es.

### Configuration Z.ai (optionnel)

Pour utiliser les mod√®les cloud GLM-4.7, configurez votre cl√© API dans `agent/.env` :

```bash
ZAI_API_KEY=sk-your-api-key
ZAI_BASE_URL=https://api.z.ai/api/coding/paas/v4
```

Sans cl√© API, le syst√®me bascule automatiquement sur les mod√®les locaux (Qwen3).

---

## üõ†Ô∏è Capacit√©s des Outils

Statut actuel : **10/11 outils c≈ìurs impl√©ment√©s**

| Outil | Statut | Description |
|-------|--------|-------------|
| **Syst√®me de Fichiers** | ‚úÖ | Lire, √©crire, d√©placer, supprimer et rechercher des fichiers sur Windows. |
| **Ex√©cution OS** | ‚úÖ | Ex√©cuter des commandes et des scripts PowerShell. |
| **Presse-papier** | ‚úÖ | Acc√©der et modifier le presse-papier Windows. |
| **Recherche Web** | ‚úÖ | Recherche web en temps r√©el via DuckDuckGo (illimit√©). |
| **Lecteur Web** | ‚úÖ | Extraction de contenu et conversion en markdown depuis des URLs. |
| **Vision** | ‚úÖ | Analyse d'images locale et OCR via `qwen3-vl`. |
| **Capture d'√âcran** | ‚úÖ | Capturer l'√©cran entier ou des r√©gions sp√©cifiques. |
| **Souris & Clavier** | ‚úÖ | Contr√¥le direct des entr√©es OS via pyautogui. |
| **Grounding GUI** | ‚úÖ | Localisation d'√©l√©ments UI avec qwen3-vl. |
| **Chrome DevTools** | ‚úÖ | Automatisation compl√®te du navigateur via MCP (Puppeteer). |
| **GitHub** | ‚è≥ | Analyse de d√©p√¥ts et lecture de fichiers (Roadmap). |

---

## üìÖ Roadmap

### Module 0 : Fondations ‚úÖ
- Structure du projet, Next.js 16, Python `uv`, et int√©gration Ollama.

### Module 1 : Cerveau Python ‚úÖ
- Int√©gration `smolagents`, serveur FastAPI, et interface de d√©veloppement Gradio.

### Module 2 : M√©moire (Prisma 7.4) ‚úÖ
- Persistance SQLite pour les conversations et les param√®tres.

### Module 3 : WebChat ‚úÖ
- Interface de streaming, SSE, et authentification s√©curis√©e.

### Module 4 : Int√©gration Nextcloud Talk ‚è≥
- Support de bot via webhooks HMAC-SHA256 pour l'interaction mobile.

### Module 5 : T√¢ches Proactives ‚è≥
- Ex√©cution de jobs bas√©s sur cron et notifications proactives.

### Module 6 : Identit√© & Persona ‚è≥
- Prompts syst√®me personnalisables et r√©glages de la personnalit√© de l'assistant.

---

## üìö Documentation

Pour des informations plus d√©taill√©es, veuillez vous r√©f√©rer aux fichiers suivants :

- üìä [STATUS.md](STATUS.md) ‚Äî Vue d'ensemble rapide du projet.
- üìã [PROGRESS.md](PROGRESS.md) ‚Äî Points d'avancement d√©taill√©s du d√©veloppement.
- üó∫Ô∏è [PLAN.md](PLAN.md) ‚Äî Architecture et objectifs √† long terme.
- üèóÔ∏è [AGENTS.md](AGENTS.md) ‚Äî Guide technique pour les d√©veloppeurs et agents.
- üéØ [agent/SKILLS.md](agent/SKILLS.md) ‚Äî Patterns de code sp√©cifiques √† l'agent.

---

## üõ†Ô∏è Stack Technique

- **Frontend** : Next.js 16.1, React 19, Tailwind CSS 4
- **Base de Donn√©es** : SQLite avec Prisma 7.4
- **Framework Agent** : [smolagents](https://github.com/huggingface/smolagents)
- **API** : FastAPI (Python)
- **Environnement** : Node.js 25+, Python 3.14.2 (via `uv`)
- **LLM** : Ollama (Local), Z.ai (Cloud/Optionnel)

---

## üìÑ Licence

Ce projet est sous licence MIT - voir le fichier [LICENSE](LICENSE) file for details.

---

Construit avec ü¶û et üêç pour une meilleure exp√©rience d'IA personnelle.
