# AGENTS.md ‚Äî my-claw Assistant Personnel Hybride
> Fichier de guidage pour les IA de codage (Kilo Code, Crush, Claude Code, Cursor, Codex, Windsurf...)
> Architecture : Next.js 16 (gateway) + Python smolagents (cerveau) + Gradio (UI dev)

---

## R√àGLES IMP√âRATIVES POUR L'IA DE CODAGE

0. **Lis LEARNING.md** - avant chaque t√¢che. Mets **LEARNING.md** √† jour avec les nouvelles d√©couvertes apr√®s.
1. **STOP √† chaque CHECKPOINT** ‚Äî attendre validation explicite de l'utilisateur avant de continuer
2. **Un module √† la fois** ‚Äî ne jamais anticiper le module suivant
3. **Lire le skill correspondant** dans `.claude/skills/` avant de coder quoi que ce soit
4. **Ne jamais impl√©menter un module V2** ‚Äî ils sont marqu√©s en attente et bloqu√©s intentionnellement
5. **uv uniquement** pour Python ‚Äî jamais pip install, jamais requirements.txt
6. **Pas de console.log** en prod c√¥t√© Next.js ‚Äî logger structur√© uniquement
7. **Pas de secrets dans le code** ‚Äî toujours process.env ou os.environ
8. **Webhooks** : r√©pondre HTTP 200 imm√©diatement, traiter en async
9. **Valider TypeScript** : npx tsc --noEmit doit passer avant chaque commit
10. **lancement serveur** : Ne jamais exectuter : **npm run** dev ou **uv run uvicorn main:app --reload**, demander √† l'utilisateur de le lancer et de donn√© les erreurs/informations
11. **max_steps** : 5 pour t√¢ches simples, 10 pour pilotage PC complexe (TOOL-9)

---

## STACK TECHNIQUE

| Couche | Technologie | Version | Notes |
|--------|-------------|---------|-------|
| Gateway | Next.js | 16+ | App Router obligatoire |
| ORM | Prisma | 7+ | SQLite local |
| Runtime JS | Node.js | 25+ | |
| Gestionnaire Python | uv | latest | Jamais pip |
| Agent LLM | smolagents | 1.24+ | CodeAgent |
| API serveur Python | FastAPI | 0.131+ | |
| UI dev | Gradio | 6+ | |
| LLM local | Ollama | latest | Port 11434 |
| LLM cloud | Z.ai GLM-4.7 | ‚Äî | OpenAI-compatible |
| Language | TypeScript | 5+ | strict: true |

---

## MOD√àLES LLM

### Ollama ‚Äî 100% local, 0 donn√©e sortante

| ID | Mod√®le | Taille | Usage |
|----|--------|--------|-------|
| | fast | gemma3:latest | 3.3GB | R√©ponses rapides |
| | smart | qwen3:8b | 5.2GB | Usage quotidien ‚Äî recommand√© |
| | main | qwen3:8b | 5.2GB | Mod√®le principal ‚Äî d√©faut sans ZAI_API_KEY |
| | vision | qwen3-vl:2b | 2.3GB | Vision locale (TOOL-7, analyse d'images) |
| | grounding | qwen3-vl:2b | 2.3GB | GUI grounding (TOOL-11, pilotage PC) |

**Note :** Les mod√®les qwen3-vl:2b sont pr√©f√©r√©s pour la vision et le grounding car ils sont plus rapides et plus l√©gers.

### Z.ai ‚Äî Cloud (donn√©es envoy√©es √† Z.ai)

| ID | Mod√®le | Usage |
|----|--------|-------|
| | code | glm-4.7-flash | Code, t√¢ches techniques rapides |
| | reason | glm-4.7 | Raisonnement profond ‚Äî d√©faut avec ZAI_API_KEY |

### Configuration du mod√®le par d√©faut

Le mod√®le par d√©faut pour le manager et tous les sous-agents est d√©termin√© par la fonction `get_default_model()` avec la priorit√© suivante :

1. **Variable d'environnement `DEFAULT_MODEL`** : Si d√©finie et valide
2. **`reason` (glm-4.7)** : Si `ZAI_API_KEY` est configur√©
3. **`main` (qwen3:8b)** : Fallback local

Exemples de configuration dans `agent/.env` :

```bash
# Utiliser glm-4.7 par d√©faut (recommand√© pour le raisonnement)
DEFAULT_MODEL=reason

# Utiliser glm-4.7-flash pour le coding rapide
DEFAULT_MODEL=code

# Forcer le mod√®le local (gratuit)
DEFAULT_MODEL=main
```

### R√®gles mod√®les

- Mod√®le par d√©faut : `reason` (glm-4.7) si ZAI_API_KEY configur√©, sinon `main` (qwen3:8b)
- **D√©tection automatique** : L'agent d√©tecte les mod√®les Ollama install√©s au d√©marrage via `GET /api/tags`
- **Pr√©f√©rences par cat√©gorie** : Chaque cat√©gorie (fast/smart/main/vision) a une liste de mod√®les pr√©f√©r√©s
- **Fallback intelligent** : Si le mod√®le pr√©f√©r√© n'est pas install√©, utilise le suivant dans la liste
- Si ZAI_API_KEY absent : fallback silencieux sur main
- think: false en mode agent (√©vite verbosit√© Qwen3)
- num_ctx: 32768 pour tous les mod√®les Ollama
- max_steps=5 pour t√¢ches simples, 10 pour pilotage PC complexe
- Provider Ollama : LiteLLMModel avec prefix ollama_chat/
- Provider Z.ai : LiteLLMModel avec prefix openai/ (compatible OpenAI)
- TOOL-7 (analyze_image) : utilise qwen3-vl:8b en local via Ollama (interne √† l'outil)
- vision_agent : utilise glm-4.7 ou qwen3:8b comme LLM, qwen3-vl:8b en interne pour la vision
- **API `/models`** : Endpoint pour r√©cup√©rer la liste des mod√®les disponibles

---

## GESTION DES MOD√àLES ‚Äî Module agent/models.py

Le module [`agent/models.py`](agent/models.py) centralise la cr√©ation et la configuration des mod√®les LLM pour √©viter les imports circulaires et la duplication de code.

### Fonctions principales

#### get_model(model_id: str = "main") -> LiteLLMModel
Cr√©e un mod√®le LiteLLMModel correctement configur√© selon l'identifiant fourni.

**Priorit√©s de s√©lection :**
1. Mod√®le sp√©cifi√© par `model_id`
2. Fallback sur "main" si mod√®le non trouv√©
3. Premier mod√®le disponible si "main" non trouv√©
4. Exception si aucun mod√®le disponible

**Comportement :**
- Mod√®les cloud (glm-4.7, glm-4.7-flash) : Utilise `CleanedLiteLLMModel` avec API Z.ai
- Mod√®les locaux (qwen3:*, gemma3:*) : Utilise `LiteLLMModel` standard avec Ollama

#### get_default_model() -> str
Retourne le mod√®le par d√©faut selon les priorit√©s :
1. Variable d'environnement `DEFAULT_MODEL`
2. "reason" (glm-4.7) si `ZAI_API_KEY` configur√©
3. "main" (qwen3:8b) en fallback local

#### detect_models() -> dict[str, tuple[str, str]]
D√©tecte automatiquement les mod√®les disponibles (Ollama + cloud).

**Pr√©f√©rences par cat√©gorie :**
```python
MODEL_PREFERENCES = {
    "fast":   ["gemma3:latest", "qwen3:4b", "gemma3n:latest"],
    "smart":  ["qwen3:8b", "qwen3:4b", "gemma3n:latest", "gemma3:latest"],
    "main":   ["qwen3:8b", "qwen3:4b", "gemma3n:latest", "gemma3:latest"],
    "vision": ["qwen3-vl:8b", "qwen3-vl:2b", "qwen3-vl:4b", "llama3.2-vision"],
}
```

### CleanedLiteLLMModel

Wrapper sp√©cial pour les mod√®les GLM-4.7 qui nettoie automatiquement les balises parasites g√©n√©r√©es par ces mod√®les.

**Balises nettoy√©es :**
- `</code>` (avec `>`)
- `</code` (sans `>`)
- `</s>`

**Exemple d'utilisation :**
```python
from models import get_model

# Pour GLM-4.7 (cloud)
model = get_model("reason")  # Retourne CleanedLiteLLMModel

# Pour qwen3:8b (local)
model = get_model("main")  # Retourne LiteLLMModel standard
```

---

## ARCHITECTURE MULTI-AGENT

Le syst√®me utilise une architecture Manager + Sous-agents sp√©cialis√©s pour optimiser l'utilisation des mod√®les et des outils.

### Manager

**R√¥le :** Orchestrateur principal qui d√©l√®gue les t√¢ches aux sous-agents appropri√©s.

**Mod√®le :** Par d√©faut (glm-4.7 avec ZAI_API_KEY, sinon qwen3:8b)

**Tools directs :**
- `file_system` : Op√©rations sur les fichiers
- `os_exec` : Ex√©cution de commandes PowerShell
- `clipboard` : Lecture/√©criture du presse-papier

**Configuration :**
```python
manager = CodeAgent(
    tools=manager_tools,
    model=get_model(model_id),
    managed_agents=managed_agents,
    max_steps=10,
    verbosity_level=2,
    additional_authorized_imports=["requests", "urllib", "json", "csv", "pathlib", "os", "subprocess"],
    executor_kwargs={"timeout_seconds": 240},
    instructions=SKILLS,
)
```

### Sous-agents

#### pc_control_agent

**Fichier :** [`agent/agents/pc_control_agent.py`](agent/agents/pc_control_agent.py)

**R√¥le :** Pilotage de l'interface graphique Windows

**Outils :**
- `screenshot` : Capture d'√©cran
- `ui_grounding` : Localisation d'√©l√©ments UI avec qwen3-vl
- `mouse_keyboard` : Contr√¥le souris/clavier

**Mod√®le :** Par d√©faut (glm-4.7 ou qwen3:8b)

**Instructions sp√©cifiques :** Workflow screenshot ‚Üí grounding ‚Üí action

**Configuration :**
```python
agent = CodeAgent(
    tools=pc_tools,
    model=get_model(model_id),
    max_steps=15,
    verbosity_level=1,
    additional_authorized_imports=["json", "re", "time", "os"],
    executor_kwargs={"timeout_seconds": 300},
    instructions=_PC_CONTROL_INSTRUCTIONS,
    name="pc_control",
    description="Agent sp√©cialis√© pour piloter l'interface graphique Windows...",
)
```

#### vision_agent

**Fichier :** [`agent/agents/vision_agent.py`](agent/agents/vision_agent.py)

**R√¥le :** Analyse d'images avec mod√®le de codage

**Outils :**
- `analyze_image` : Analyse d'images (qwen3-vl:8b interne)

**Mod√®le :** Par d√©faut (glm-4.7 ou qwen3:8b) - mod√®le de CODAGE
**Note :** L'outil `analyze_image` utilise son propre mod√®le de vision (qwen3-vl:8b)

**Configuration :**
```python
agent = CodeAgent(
    tools=vision_tools,
    model=get_model(model_id),
    max_steps=5,
    verbosity_level=1,
    additional_authorized_imports=["json", "re", "time", "os"],
    executor_kwargs={"timeout_seconds": 180},
    instructions=_VISION_INSTRUCTIONS,
    name="vision",
    description="Agent sp√©cialis√© dans l'analyse d'images...",
)
```

#### browser_agent

**Fichier :** [`agent/agents/browser_agent.py`](agent/agents/browser_agent.py)

**R√¥le :** Automatisation de Chrome via DevTools MCP

**Outils :** 26 outils Chrome DevTools MCP (navigation, click, fill, screenshot, snapshot...)

**Mod√®le :** Par d√©faut (glm-4.7 ou qwen3:8b)

**Configuration :**
```python
agent = CodeAgent(
    tools=mcp_tools,
    model=get_model(model_id),
    max_steps=12,
    verbosity_level=1,
    additional_authorized_imports=["json", "re", "time"],
    executor_kwargs={"timeout_seconds": 240},
    instructions=_BROWSER_INSTRUCTIONS,
    name="browser",
    description="Agent sp√©cialis√© dans l'automatisation de Chrome...",
)
```

#### web_agent

**Fichier :** [`agent/agents/web_agent.py`](agent/agents/web_agent.py)

**R√¥le :** Recherche web et lecture de contenu via MCP Z.ai

**Outils :** (si ZAI_API_KEY configur√©)
- `webSearchPrime` : Recherche web temps r√©el
- `webReader` : Lecture de pages web
- `zread` : Lecture de repos GitHub

**Mod√®le :** Par d√©faut (glm-4.7 ou qwen3:8b)

**Note :** Retourne `None` si aucun tool MCP Z.ai n'est disponible

### D√©l√©gation automatique

Le Manager d√©l√®gue automatiquement les t√¢ches aux sous-agents appropri√©s selon leur description et leurs outils.

**Exemples :**
- "Ouvre Notepad" ‚Üí D√©l√©gu√© √† `pc_control_agent`
- "Analyse cette image" ‚Üí D√©l√©gu√© √† `vision_agent`
- "Ouvre https://example.com" ‚Üí D√©l√©gu√© √† `browser_agent`
- "Recherche des infos sur smolagents" ‚Üí D√©l√©gu√© √† `web_agent` (si disponible)

---

## SKILLS ‚Äî Patterns de code r√©utilisables

Le syst√®me de skills fournit des patterns de code concrets √† l'agent pour √©viter qu'il r√©g√©n√®re le m√™me code √† chaque fois.

### Pourquoi des skills ?

Les LLM ont tendance √† r√©g√©n√©rer le code √† chaque fois, ce qui :
- ‚ùå Prend du temps (g√©n√©ration LLM)
- ‚ùå Consomme des tokens inutilement
- ‚ùå Peut introduire des erreurs ou variations

En fournissant des patterns de code concrets, l'agent peut :
- ‚úÖ Copier directement le code sans le r√©g√©n√©rer
- ‚úÖ Ex√©cuter plus rapidement
- ‚úÖ √ätre plus fiable et coh√©rent
- ‚úÖ √âconomiser des tokens

### Architecture

```
agent/
‚îú‚îÄ‚îÄ skills.txt          ‚Üê Patterns de code charg√©s au d√©marrage
‚îú‚îÄ‚îÄ SKILLS.md           ‚Üê Documentation des skills
‚îî‚îÄ‚îÄ main.py             ‚Üê Charge skills.txt via load_skills()
```

### Flux de chargement

1. Au d√©marrage, `main.py` appelle `load_skills()`
2. `load_skills()` lit `agent/skills.txt`
3. Le contenu est stock√© dans la variable `SKILLS`
4. `SKILLS` est pass√© au param√®tre `instructions` de `CodeAgent`
5. L'agent re√ßoit les patterns et peut les copier directement

### Skills disponibles

Voir [`agent/SKILLS.md`](agent/SKILLS.md) pour la documentation compl√®te des skills disponibles :
1. Screenshot + Vision
2. OCR (Extraction de texte)
3. Screenshot d'une r√©gion sp√©cifique
4. Requ√™te HTTP avec Python
5. Ouvrir une application avec le clavier

### Comment ajouter un nouveau skill ?

1. Identifier un pattern r√©p√©titif
2. Cr√©er un exemple concret (code minimal et fonctionnel)
3. Ajouter dans `agent/skills.txt`
4. Red√©marrer le serveur : `uv run uvicorn main:app --reload`
5. Documenter dans `agent/SKILLS.md`
6. Tester : V√©rifier que l'agent copie bien le pattern

**Avantage** : Pas besoin de modifier le code Python, juste √©diter `skills.txt` !

---

## SCH√âMA BASE DE DONN√âES

### Prisma 7 ‚Äî Points critiques
- url dans schema.prisma n'existe plus
- La connexion se configure dans gateway/prisma.config.ts via datasource.url
- adapter, earlyAccess, engine sont supprim√©s en v7
- PrismaLibSQL prend { url: string } directement, pas besoin de createClient()

### Table Conversation
- id : cuid, PK
- channel : "webchat" | "nextcloud"
- channelId : identifiant unique par canal (session, num√©ro, username)
- title : r√©sum√© auto, optionnel
- model : mod√®le par d√©faut "main"
- createdAt, updatedAt
- Index unique sur [channel, channelId]

### Table Message
- id : cuid, PK
- conversationId : FK vers Conversation (cascade delete)
- role : "user" | "assistant"
- content : texte
- model : mod√®le utilis√©, optionnel
- createdAt
- Index sur [conversationId, createdAt]

### Table CronJob
- id : cuid, PK
- name : unique
- schedule : expression cron ex "0 9 * * 1-5"
- prompt : instruction √† ex√©cuter
- channel + channelId : destinataire
- model : d√©faut "main"
- enabled : boolean
- lastRun : datetime optionnel

### Table Settings
- key : PK string
- value : string
- updatedAt
- Utilis√© pour : system_prompt, persona_name, persona_lang

---

## CANAUX

### WebChat
- Auth : header Authorization: Bearer {WEBCHAT_TOKEN}
- Streaming via Server-Sent Events (ReadableStream)
- Token minimum 32 chars

### Nextcloud Talk Bot
- POST /api/webhook/nextcloud : v√©rifier signature HMAC-SHA256 obligatoire
- Headers √† v√©rifier : X-Nextcloud-Talk-Random + X-Nextcloud-Talk-Signature
- Secret partag√© : NEXTCLOUD_BOT_SECRET
- Envoi : POST {NC_BASE_URL}/ocs/v2.php/apps/spreed/api/v1/bot/{BOT_ID}/message
- Header envoi : OCS-APIRequest: true
- Utiliser crypto.timingSafeEqual pour comparer les signatures

---

## FLUX /api/chat

1. Recevoir { message, conversationId?, model?, channel, channelId }
2. Cr√©er ou r√©cup√©rer la Conversation (Prisma)
3. Sauvegarder le message user en DB
4. R√©cup√©rer les 20 derniers messages (contexte glissant)
5. R√©cup√©rer le system prompt depuis Settings
6. Appeler agent Python POST /run avec { message, history, model }
7. Sauvegarder la r√©ponse assistant en DB
8. Retourner la r√©ponse (stream SSE pour webchat, JSON pour les autres)

---

## OUTILS smolagents

### V1 ‚Äî Actifs (impl√©ment√©s et valid√©s)
- **FileSystemTool** (TOOL-1) : read/write/create/delete/list/move/search
- **OsExecTool** (TOOL-2) : ex√©cution PowerShell
- **ClipboardTool** (TOOL-3) : lecture/√©criture presse-papier
- **ScreenshotTool** (TOOL-8) : capture d'√©cran Windows
- **VisionTool** (TOOL-7) : analyse d'images locale avec qwen3-vl (100% local, 0 donn√©e sortante)
- **QwenGroundingTool** (TOOL-11) : GUI grounding avec qwen3-vl
- **ChromeDevTools MCP** (TOOL-10) : pilotage Chrome via Puppeteer (26 outils)

**26 outils Chrome DevTools MCP organis√©s en 6 cat√©gories :**

**Input automation (8 outils) :**
- `click` : cliquer sur un √©l√©ment (uid, dblClick?, includeSnapshot?)
- `drag` : glisser un √©l√©ment vers un autre (from_uid, to_uid)
- `fill` : remplir un champ de saisie (uid, value)
- `fill_form` : remplir plusieurs champs √† la fois (elements[])
- `handle_dialog` : g√©rer les bo√Ætes de dialogue (action: accept/dismiss)
- `hover` : survoler un √©l√©ment (uid)
- `press_key` : appuyer sur une touche ou combinaison (key: "Enter", "Control+A")
- `upload_file` : uploader un fichier (filePath, uid)

**Navigation automation (6 outils) :**
- `close_page` : fermer une page (pageId)
- `list_pages` : lister les pages ouvertes
- `navigate_page` : naviguer vers une URL (type: url/back/forward/reload)
- `new_page` : cr√©er une nouvelle page (url)
- `select_page` : s√©lectionner une page comme contexte (pageId)
- `wait_for` : attendre qu'un texte apparaisse (text, timeout?)

**Emulation (2 outils) :**
- `emulate` : √©muler diverses fonctionnalit√©s (cpuThrottlingRate?, geolocation?, networkConditions?)
- `resize_page` : redimensionner la page (width, height)

**Performance (3 outils) :**
- `performance_analyze_insight` : analyser une insight de performance (insightName, insightSetId)
- `performance_start_trace` : d√©marrer un enregistrement de trace (autoStop, reload)
- `performance_stop_trace` : arr√™ter l'enregistrement de trace

**Network (2 outils) :**
- `get_network_request` : r√©cup√©rer une requ√™te r√©seau (reqid?)
- `list_network_requests` : lister les requ√™tes (pageIdx?, pageSize?, resourceTypes[]?)

**Debugging (5 outils) :**
- `evaluate_script` : ex√©cuter du JavaScript (function)
- `get_console_message` : r√©cup√©rer un message console (msgid)
- `list_console_messages` : lister les messages console (pageIdx?, pageSize?, types[]?)
- `take_screenshot` : prendre un screenshot (format, fullPage?, quality?, uid?)
- `take_snapshot` : prendre un snapshot textuel de la page (verbose?)

### V1 ‚Äî En cours (non valid√©)
- **MouseKeyboardTool** (TOOL-9) : üîÑ contr√¥le souris/clavier (n√©cessite orchestration)

### V1 ‚Äî Roadmap (√Ä venir)
- **Web Search MCP** (TOOL-4) : ‚è≥ recherche web Z.ai
- **Web Reader MCP** (TOOL-5) : ‚è≥ lecture URL Z.ai
- **Zread MCP** (TOOL-6) : ‚è≥ lecture GitHub Z.ai

### V2 ‚Äî Bloqu√©s, ne pas impl√©menter
- run_code sandbox Python/Node
- read_file / write_file dossier whitelist

### R√®gles de codage outils
- Toujours sous-classe Tool (pas d√©corateur @tool) pour compatibilit√© Ollama
- Imports dans forward(), pas au top-level du fichier
- Timeout 10s sur tous les appels HTTP
- max_steps=5 pour t√¢ches simples, 10 pour pilotage PC complexe
- pyautogui.FAILSAFE=False configur√© (pas de coin haut-gauche pour arr√™ter)
- time.sleep(0.5) apr√®s chaque action pyautogui pour laisser l'OS r√©agir
- Logs de debug ajout√©s dans mouse_keyboard.py pour diagnostiquer les probl√®mes

---

## VARIABLES D'ENVIRONNEMENT

### gateway/.env.local
- DATABASE_URL : file:./prisma/dev.db
- WEBCHAT_TOKEN : min 32 chars (openssl rand -hex 32)
- CRON_SECRET : min 32 chars
- AGENT_URL : http://localhost:8000
- NEXTCLOUD_BASE_URL
- NEXTCLOUD_BOT_SECRET
- NEXTCLOUD_BOT_ID
- SCREENSHOT_DIR : C:\tmp\myclawshots (optionnel, d√©faut: C:\tmp\myclawshots)

### agent/.env
- OLLAMA_BASE_URL : http://localhost:11434
- ZAI_API_KEY : optionnel
- ZAI_BASE_URL : https://api.z.ai/api/coding/paas/v4
- DEFAULT_MODEL : mod√®le par d√©faut (optionnel, d√©faut: reason si ZAI_API_KEY, sinon main)
- SCREENSHOT_DIR : C:\tmp\myclawshots (d√©faut)

---

## CONVENTIONS DE CODE

### Python
- Python 3.14+, type hints partout
- pyproject.toml + uv.lock ‚Äî jamais requirements.txt
- uv add <pkg> pour ajouter une d√©pendance
- uv run <cmd> pour ex√©cuter
- Logging via module logging, pas print()

### TypeScript
- strict: true dans tsconfig
- Exports nomm√©s, pas de default sauf pages Next.js
- unknown + type guard, jamais any

### S√©curit√©
- Ne jamais logger le contenu des messages
- Logger uniquement : canal, timestamp, dur√©e, mod√®le
- Valider signature/token sur tous les webhooks
- pyautogui.FAILSAFE=False configur√© (pas de coin haut-gauche pour arr√™ter)
- time.sleep(0.5) apr√®s chaque action pyautogui pour laisser l'OS r√©agir

---

## CE QU'ON NE FAIT PAS

- Pas de multi-utilisateurs
- Pas de Docker pour l'app principale
- Pas de Redis ou message queue
- Pas de pip install ou requirements.txt
- Pas de features V2 sans validation explicite
- Pas de Telegram, Discord, Slack, Signal
- Pas de pilotage PC sans Vision (TOOL-7 requis pour TOOL-9)

---

## CHECKLIST AVANT COMMIT

- npx tsc --noEmit passe sans erreur (gateway)
- Les deux services d√©marrent sans erreur
- Nouvelles variables d'env dans .env.example
- Pas de secrets dans le code
- Webhooks v√©rifient leur signature/token
- CHECKPOINT du module valid√© par l'utilisateur

---

## R√âF√âRENCES

- smolagents : https://huggingface.co/docs/smolagents
- smolagents MCP : https://huggingface.co/docs/smolagents/tutorials/mcp
- Prisma 7 Config : https://pris.ly/d/config-datasource
- Z.ai GLM-4.7 : https://open.bigmodel.cn/dev/api
- Ollama API : https://github.com/ollama/ollama/blob/main/docs/api.md
- Nextcloud Talk Bot : https://nextcloud-talk.readthedocs.io/en/latest/bot-list/
- Prisma 7 Docs : https://www.prisma.io/docs
- Next.js 16 : https://nextjs.org/docs/app
- Gradio : https://www.gradio.app/docs
- FastAPI : https://fastapi.tiangolo.com
- pyautogui : https://pyautogui.readthedocs.io
- Pillow : https://pillow.readthedocs.io
